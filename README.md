# Next_Word_Prediction_using_LSTM

## Project Overview:
Developed a next word prediction model leveraging Long Short-Term Memory (LSTM) neural networks to predict the subsequent word in a given sequence. This model is ideal for applications such as predictive text input and text generation.

## Key Features:

LSTM Network: Utilized LSTM layers to capture long-term dependencies in text sequences, enabling accurate next-word predictions.
Data Preprocessing: Implemented tokenization and padding to prepare the text data for model training.
High Accuracy: Achieved an accuracy of approximately 87.44% on the training dataset after 80 epochs.
Multi-word Prediction: Capable of predicting the next five words in a given seed text sequence.
Technologies Used:

## Programming Language: Python
Deep Learning Framework: TensorFlow/Keras
Natural Language Processing: Tokenization, sequence padding

##Model Performance:

Training Accuracy: 87.44% after 80 epochs


This project showcases the application of LSTM networks in natural language processing tasks and highlights my skills in deep learning, text preprocessing, and model evaluation. The complete implementation, including data preprocessing and model training, is available on my GitHub repository.
